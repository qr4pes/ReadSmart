
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   WEBSITE CONTENT ANALYZER                         â•‘
â•‘                     Quick Getting Started                          â•‘
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

âœ¨ WHAT YOU'VE GOT

A complete, production-ready web application that analyzes website 
content for:
  â€¢ Credibility (scored 0-100)
  â€¢ Propaganda detection  
  â€¢ Out-of-context information
  â€¢ Content categorization

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ QUICKEST START (5 MINUTES)

1. Get an OpenAI API key:
   â†’ https://platform.openai.com/api-keys

2. Create .env file:
   $ cp .env.example .env
   
3. Edit .env and add your key:
   OPENAI_API_KEY=sk-your-key-here

4. Start with Docker:
   $ docker-compose up -d

5. Open in browser:
   â†’ http://localhost:8000

That's it! You're running.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“š DOCUMENTATION FILES

Read these in order:

1. QUICKSTART.md         â† Start here (5 min setup)
2. README.md             â† Full documentation
3. PROJECT_SUMMARY.md    â† What's been built
4. ARCHITECTURE.md       â† System design
5. AWS_DEPLOYMENT.md     â† Production deployment

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ—ï¸  PROJECT STRUCTURE

website-analyzer/
â”œâ”€â”€ backend/              Python FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py      FastAPI app
â”‚   â”‚   â”œâ”€â”€ models.py    Database models
â”‚   â”‚   â”œâ”€â”€ api/         API endpoints
â”‚   â”‚   â””â”€â”€ services/    Core services
â”‚   â”‚       â”œâ”€â”€ scraper.py   Web scraping
â”‚   â”‚       â”œâ”€â”€ chunker.py   Content splitting
â”‚   â”‚       â””â”€â”€ analyzer.py  AI analysis
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/            Static HTML/CSS/JS
â”‚   â”œâ”€â”€ index.html       Main page
â”‚   â”œâ”€â”€ styles.css       Styling
â”‚   â””â”€â”€ app.js           Client logic
â”‚
â”œâ”€â”€ docker-compose.yml   Local development setup
â””â”€â”€ .env                 Configuration (create this!)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”§ COMMON COMMANDS

Start application:
  $ docker-compose up -d

View logs:
  $ docker-compose logs -f backend

Stop application:
  $ docker-compose down

Reset everything:
  $ docker-compose down -v
  $ docker-compose up -d

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŒ ACCESS POINTS

Frontend:     http://localhost:8000
API Docs:     http://localhost:8000/docs  (Swagger UI)
API Base:     http://localhost:8000/api
Health Check: http://localhost:8000/api/health

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ WHAT IT DOES

1. User enters a website URL
2. Backend scrapes the website content
3. Content is split into chunks (for large pages)
4. Each chunk is analyzed by GPT-4 for:
   - Credibility indicators
   - Propaganda techniques
   - Out-of-context information
   - Overall context
5. Results are aggregated and stored
6. User sees a comprehensive credibility report

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ TECH STACK

Backend:   Python, FastAPI, SQLAlchemy, PostgreSQL
Frontend:  HTML, CSS, JavaScript (Vanilla)
AI:        OpenAI GPT-4 API
Deploy:    Docker, AWS ECS/Fargate, RDS

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš™ï¸  CUSTOMIZATION

Change AI model (backend/app/services/analyzer.py):
  self.model = "gpt-3.5-turbo"  # Cheaper, faster

Adjust chunking (backend/app/services/chunker.py):
  ContentChunker(max_tokens=3000, overlap=200)

Change port (docker-compose.yml):
  ports:
    - "8080:8000"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ï¿½ï¿½ TROUBLESHOOTING

Problem: "Docker is not running"
â†’ Start Docker Desktop

Problem: "Analysis failed"
â†’ Check OPENAI_API_KEY in .env
â†’ Verify you have API credits

Problem: Database errors
â†’ Reset: docker-compose down -v && docker-compose up -d

Problem: Port 8000 in use
â†’ Change port in docker-compose.yml

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â˜ï¸  AWS DEPLOYMENT

Ready to deploy to production?

See AWS_DEPLOYMENT.md for complete guide covering:
  â€¢ VPC and networking setup
  â€¢ RDS PostgreSQL database
  â€¢ ECS Fargate containers
  â€¢ Application Load Balancer
  â€¢ Domain and HTTPS setup
  â€¢ Cost estimation (~$130/month + OpenAI)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… REQUIREMENTS MET

âœ“ User-facing web interface
âœ“ Backend Python services
âœ“ Content analysis (out-of-context, propaganda, credibility)
âœ“ Content reading and chunking
âœ“ AI service integration (OpenAI)
âœ“ PostgreSQL database tracking
âœ“ Simple HTML frontend
âœ“ AWS deployment ready
âœ“ Local running version
âœ“ Clean UI/UX

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ NEED HELP?

1. Check QUICKSTART.md for setup issues
2. Read README.md for detailed info
3. Review logs: docker-compose logs -f backend
4. Check API docs: http://localhost:8000/docs

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Happy analyzing! ğŸ”

